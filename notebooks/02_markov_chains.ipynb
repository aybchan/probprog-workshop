{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Markov chains and their stationary distributions\n",
    "\n",
    "Interactive demo:\n",
    "\n",
    "http://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.1%2C0.1%2C0.8%5D%2C%5B0.5%2C0.3%2C0.2%5D%2C%5B0.7%2C0.1%2C0.2%5D%5D%7D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Define a transition matrix, `M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# markov transition matrix\n",
    "M = np.array([[0.1,0.1,0.8],\n",
    "              [0.5,0.3,0.2],\n",
    "              [0.7,0.1,0.2]])\n",
    "\n",
    "# each state (row) should have a value (col) for each state\n",
    "assert M.shape[0]==M.shape[1], 'M should be a square matrix'\n",
    "\n",
    "# make sure each row is a valid probability distribution\n",
    "# (i.e. sums to 1)\n",
    "M = M/np.sum(M,axis=1)[np.newaxis].T\n",
    "assert np.allclose(np.sum(M,axis=1),np.ones(len(M)))\n",
    "\n",
    "print('Transition matrix:')\n",
    "print([list(i) for i in M])\n",
    "\n",
    "# init location\n",
    "x = np.random.uniform(0,1,3)\n",
    "x = x/np.array(x).sum()\n",
    "print('\\nInitial state probability')\n",
    "print('A: {0:.1f}%  B: {1:.1f}%  C: {2:.1f}%'.format(*x*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_to_convergence(init,transition_matrix):\n",
    "    alphabet = 'A B C D E F G H'.split() # up to 8 states\n",
    "    n_states = len(init)\n",
    "    converged = False\n",
    "    n = 0\n",
    "    x = init\n",
    "    \n",
    "    print('\\t\\tAmount of time spent in state:')\n",
    "    print('\\t'*3 + '\\t'.join(alphabet[:n_states]))\n",
    "    while not converged:\n",
    "        for i in range(5):\n",
    "            x = x @ transition_matrix\n",
    "            print('After {0: 4} transitions:\\t'\n",
    "                  .format(n+i),end='')\n",
    "            print('\\t'.join(['{{{0}:.1f}}%'.format(i) for i in range(n_states)]).format(*x*100),end='\\t')\n",
    "            if np.allclose(x,x @ transition_matrix):\n",
    "                print('converged!',end='')\n",
    "                converged = True\n",
    "            print()\n",
    "        n += 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theory: Applying $x := x^\\top M$ repeatedly will lead to the stationary distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_to_convergence(init=?,\n",
    "                   transition_matrix=?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the proportion of time spent in each of the state converges, we say that the Markov chain has a stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Change the initial state probability\n",
    "\n",
    "Does it still converge to the __same__ stationary distribution as above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = [?, ?, ?]\n",
    "\n",
    "assert len(new_x) == M.shape[0]\n",
    "new_x = new_x/np.array(new_x).sum()\n",
    "\n",
    "print('Initial state probability')\n",
    "print('A: {0:.1f}%  B: {1:.1f}%  C: {2:.1f}%'.format(*x*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_to_convergence(init=new_x,\n",
    "                   transition_matrix=M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Define your own transition matrix\n",
    "\n",
    "Try a 4 state Markov chain (requires a 4x4 matrix) and test this in the interactive demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markov transition matrix\n",
    "M = np.array([[?, ?, ?, ?],\n",
    "              [?, ?, ?, ?],\n",
    "              [?, ?, ?, ?],\n",
    "              [?, ?, ?, ?]])\n",
    "\n",
    "# each state (row) should have a value (col) for each state\n",
    "assert M.shape[0]==M.shape[1], 'M should be a square matrix'\n",
    "\n",
    "# make sure each row is a valid probability distribution\n",
    "# (i.e. sums to 1)\n",
    "M = M/np.sum(M,axis=1)[np.newaxis].T\n",
    "assert np.allclose(np.sum(M,axis=1),np.ones(len(M)))\n",
    "\n",
    "\n",
    "print('Your Markov chain transition matrix:')\n",
    "print([list(i) for i in M])\n",
    "\n",
    "# init location\n",
    "x = [?, ?, ?, ?]\n",
    "x = x/np.array(x).sum()\n",
    "\n",
    "print('\\nInitial state probability')\n",
    "print('A: {0:.1f}%  B: {1:.1f}%  C: {2:.1f}%  D: {3:.1f}%'.format(*x*100))\n",
    "\n",
    "\n",
    "run_to_convergence(init=x,\n",
    "                   transition_matrix=M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste your printed transition matrix into the interactive demo:\n",
    "\n",
    "http://setosa.io/markov/index.html\n",
    "\n",
    "Does the demo reflect the converged stationary distirbution?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
